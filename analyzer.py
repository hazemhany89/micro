"""
analyzer.py

Provides an advanced function to analyze demand vs supply and suggest content opportunities.
Now includes combined analysis of YouTube videos and Google News articles.
"""

import re
from collections import Counter
from datetime import datetime, timedelta
from textblob import TextBlob # For sentiment analysis
import numpy as np # For median calculation
import pandas as pd # For data manipulation

def analyze_opportunity(demand_score: float, video_count: int, total_views: int,
                        video_titles: list = None, channel_names: list = None,
                        published_times: list = None, video_views_list: list = None,
                        article_count: int = 0, article_titles: list = None,
                        article_sources: list = None, article_dates: list = None) -> dict:
    """
    Analyzes demand vs supply and generates an intelligent, human-readable message
    (Arabic preferred, with emojis) to assess content opportunity.
    Now includes combined analysis of YouTube videos and Google News articles.

    Args:
        demand_score (float): Google Trends demand score (0-100).
        video_count (int): Number of top YouTube videos found.
        total_views (int): Total view count of the top YouTube videos.
        video_titles (list, optional): List of strings representing titles of the top videos.
                                       Used to detect repetition. Defaults to None.
        channel_names (list, optional): List of strings representing channel names of the top videos.
                                        Used to detect channel monopolization. Defaults to None.
        published_times (list, optional): List of strings representing published times (e.g., "3 days ago").
                                          Used to detect recent activity. Defaults to None.
        video_views_list (list, optional): List of integers representing individual video views.
                                           Used for median calculation. Defaults to None.
        article_count (int, optional): Number of Google News articles found. Defaults to 0.
        article_titles (list, optional): List of strings representing titles of the news articles.
                                         Used for content analysis. Defaults to None.
        article_sources (list, optional): List of strings representing sources of the news articles.
                                          Used to detect source diversity. Defaults to None.
        article_dates (list, optional): List of strings representing publication dates of the news articles.
                                        Used to detect recent activity. Defaults to None.

    Returns:
        dict: Contains 'opportunity_message' (str) and 'insights' (dict, optional).
    """
    opportunity_message = ""
    insights = {}

    # --- 1. Basic Calculations ---
    # YouTube metrics
    avg_views_per_video = total_views / video_count if video_count > 0 else 0
    insights['average_views_per_video'] = round(avg_views_per_video)
    insights['demand_score'] = demand_score
    insights['video_count'] = video_count
    insights['total_views'] = total_views

    # Median Views
    median_views = np.median(video_views_list) if video_views_list and len(video_views_list) > 0 else 0
    insights['median_views'] = int(median_views)
    
    # Google News metrics
    insights['article_count'] = article_count
    
    # Combined supply metrics
    total_content_count = video_count + article_count
    insights['total_content_count'] = total_content_count
    
    # Calculate content diversity ratio (videos vs articles)
    if total_content_count > 0:
        video_percentage = (video_count / total_content_count) * 100
        article_percentage = (article_count / total_content_count) * 100
        insights['video_percentage'] = round(video_percentage, 1)
        insights['article_percentage'] = round(article_percentage, 1)
        insights['content_diversity'] = 'Balanced' if 40 <= video_percentage <= 60 else ('Video-dominated' if video_percentage > 60 else 'Article-dominated')
    else:
        insights['video_percentage'] = 0
        insights['article_percentage'] = 0
        insights['content_diversity'] = 'No content'


    # --- 2. Core Decision Logic (Combined YouTube + News Analysis) ---

    # If no data at all
    if demand_score == 0 and total_content_count == 0:
        opportunity_message = "ğŸ¤·â€â™€ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø·Ù„Ø¨ Ø£Ùˆ Ù…Ø­ØªÙˆÙ‰ Ù„Ù‡Ø°Ø§ Ø§Ù„ÙƒÙ„Ù…Ø©. Ø­Ø§ÙˆÙ„ Ø¨ÙƒÙ„Ù…Ø© Ø£Ø®Ø±Ù‰."
        insights['opportunity_type'] = "No Data"
    # High Opportunity (Golden)
    elif demand_score > 70 and total_content_count <= 15 and total_views < 2_000_000 and avg_views_per_video < 100_000:
        opportunity_message = "ğŸ’¥ ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ©: Ø§Ù„Ø·Ù„Ø¨ Ù…Ø±ØªÙØ¹ ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ù‚Ù„ÙŠÙ„ Ù†Ø³Ø¨ÙŠÙ‹Ø§ (Ø¹Ø¯Ø¯ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙˆÙ…Ù‚Ø§Ù„Ø§Øª Ù‚Ù„ÙŠÙ„). Ø£Ù†Ø´Ø¦ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¢Ù† Ù‚Ø¨Ù„ Ø§Ù„Ø²Ø­Ù…Ø©!"
        insights['opportunity_type'] = "Golden Opportunity"
    # Crowded Market (High Demand, High Supply)
    elif demand_score > 70 and (total_content_count > 30 or total_views > 10_000_000 or avg_views_per_video > 500_000):
        opportunity_message = "ğŸ§  Ø³ÙˆÙ‚ Ù…Ø²Ø¯Ø­Ù…: Ø§Ù„Ø·Ù„Ø¨ ÙƒØ¨ÙŠØ±ØŒ Ù„ÙƒÙ† ÙÙŠÙ‡ Ù…Ø­ØªÙˆÙ‰ ÙƒØªÙŠØ± (ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙˆÙ…Ù‚Ø§Ù„Ø§Øª ÙƒØ«ÙŠØ±Ø©). Ø¹Ø§ÙŠØ² ØªØªÙ…ÙŠØ² ÙØ¹Ù„Ù‹Ø§!"
        insights['opportunity_type'] = "Crowded Market"
    # No Opportunity (Low Demand)
    elif demand_score < 30:
        opportunity_message = "âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙØ±ØµØ© Ø­Ø§Ù„ÙŠÙ‹Ø§: Ø§Ù„Ø·Ù„Ø¨ Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹."
        insights['opportunity_type'] = "No Opportunity"
    # Moderate Opportunity (Default)
    else:
        opportunity_message = "ğŸ¤” Ø§Ù„ÙØ±ØµØ© Ù…ØªÙˆØ³Ø·Ø©: Ø§Ù„Ø·Ù„Ø¨ ÙˆØ§Ù„Ø¹Ø±Ø¶ Ù…ØªÙˆØ§Ø²Ù†Ø§Ù†. Ù„Ùˆ Ù‡ØªÙ‚Ø¯Ù… Ù…Ø­ØªÙˆÙ‰ Ù…Ø®ØªÙ„Ù ÙˆÙØ±ÙŠØ¯ØŒ Ø¬Ø±Ø¨."
        insights['opportunity_type'] = "Moderate Opportunity"
        
    # Add content diversity insight to the message
    if total_content_count > 0:
        if insights['content_diversity'] == 'Video-dominated' and insights['video_percentage'] > 80:
            opportunity_message += "\n\nğŸ“¹ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ({}%). Ù‚Ø¯ ØªÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ ÙØ±ØµØ© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§Ù„Ø§Øª ÙˆÙ…Ø­ØªÙˆÙ‰ Ù…ÙƒØªÙˆØ¨.".format(round(insights['video_percentage']))
        elif insights['content_diversity'] == 'Article-dominated' and insights['article_percentage'] > 80:
            opportunity_message += "\n\nğŸ“° Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù…Ù‚Ø§Ù„Ø§Øª ({}%). Ù‚Ø¯ ØªÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ ÙØ±ØµØ© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø±Ø¦ÙŠ/ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª.".format(round(insights['article_percentage']))
        elif insights['content_diversity'] == 'Balanced':
            opportunity_message += "\n\nâš–ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ù‚Ø§Ù„Ø§Øª. Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ù„ØªÙ…ÙŠØ² ÙÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ±ÙŠØ¯."

    # --- 3. Advanced Analysis and Refinements ---

    # Warning for low engagement despite demand (using median views for robustness)
    if demand_score > 50 and median_views > 0 and median_views < 20_000:
        insights['low_engagement_warning'] = True
        if "ÙØ±ØµØ© Ø°Ù‡Ø¨ÙŠØ©" in opportunity_message:
            opportunity_message += "\n\nÙ„ÙƒÙ† Ø§Ù†ØªØ¨Ù‡: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ÙˆØ§Ø­Ø¯ Ù…Ù†Ø®ÙØ¶ (Ø§Ù„Ù…ØªÙˆØ³Ø·: {:,})ØŒ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ù„Ø¶Ø¹Ù ÙÙŠ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø£Ùˆ Ø¹Ø¯Ù… ØªÙØ§Ø¹Ù„ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± ğŸ“‰.".format(insights['average_views_per_video'])
        else:
            opportunity_message += "\n\nâš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ÙˆØ§Ø­Ø¯ Ù…Ù†Ø®ÙØ¶ (Ø§Ù„Ù…ØªÙˆØ³Ø·: {:,}). Ù‚Ø¯ ÙŠØ´ÙŠØ± Ù„Ø¶Ø¹Ù ÙÙŠ ØªÙØ§Ø¹Ù„ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ù…Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ğŸ“‰.".format(insights['average_views_per_video'])


    # Title Keyword Analysis & Repetition Detection (Refined)
    if video_titles and video_count > 1:
        all_words = []
        for title in video_titles:
            words = re.findall(r'\b\w+\b', title.lower())
            all_words.extend(words)

        # Expanded stopwords for Arabic and English
        stopwords = {
            "the", "a", "an", "is", "of", "in", "to", "for", "and", "or", "how", "what", "where", "why", "who", "with",
            "Ø¹Ù„Ù‰", "Ù…Ù†", "ÙÙŠ", "Ø¥Ù„Ù‰", "Ø¹Ù†", "Ù…Ø¹", "Ø£Ù†", "Ù„Ø§", "Ø¨ÙŠÙ†", "Ø£Ùˆ", "Ù‡Ùˆ", "Ù‡ÙŠ", "Ù‡Ù…", "Ù„ÙƒÙ†", "Ù‡Ø°Ø§", "Ù‡Ø°Ù‡", "Ø°Ù„Ùƒ", "Ø´Ø±Ø­", "ÙƒÙŠÙ", "Ù…Ø§", "Ø£ÙØ¶Ù„", "ØªÙØ³ÙŠØ±", "Ø¯Ù„ÙŠÙ„", "ÙƒØ§Ù…Ù„",
            "2024", "2025", "tutorial", "guide", "learn", "how to", "best", "top", "review", "new", "free", "vs", "vs.", "vs",
            "Ø´Ø§Ù‡Ø¯", "Ø­ØµØ±ÙŠØ§", "Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", "ÙƒÙ„", "Ø´ÙŠØ¡", "Ø³Ø±", "Ø§Ø³Ø±Ø§Ø±", "Ù†ØµØ§Ø¦Ø­", "Ø·Ø±Ù‚", "Ø£Ø®Ø¨Ø§Ø±", "Ø£Ù‡Ù…", "Ø¢Ø®Ø±", "Ø£ÙˆÙ„", "Ø®Ø·ÙˆØ§Øª", "Ø³Ø±ÙŠØ¹", "Ø³Ù‡Ù„", "Ø¨Ø¯ÙˆÙ†", "Ù„Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ†", "Ø§Ø­ØªØ±Ø§ÙÙŠ"
        }

        meaningful_words = [word for word in all_words if word not in stopwords and len(word) > 2]
        word_counts = Counter(meaningful_words)

        insights['most_frequent_keywords'] = word_counts.most_common(5) # Top 5 common keywords

        # Heuristic for repetition: if a "meaningful" word appears in a high percentage (e.g., > 60%) of the titles,
        # it suggests a lack of title diversity.
        repetitive_words = [word for word, count in word_counts.items() if count >= (video_count * 0.6)]

        if repetitive_words:
            insights['title_repetition_detected'] = True
            insights['repetitive_words'] = repetitive_words
            repetitive_words_str = ', '.join(repetitive_words[:3])
            opportunity_message += f"\n\nğŸ’¡ Ù†ØµÙŠØ­Ø© Ø¥Ø¶Ø§ÙÙŠØ©: Ù„Ø§Ø­Ø¸Ù†Ø§ ØªÙƒØ±Ø§Ø± Ø¨Ø¹Ø¶ Ø§Ù„ÙƒÙ„Ù…Ø§Øª/Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… ÙÙŠ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Ù…Ø«Ù„: {repetitive_words_str}). ÙÙƒØ± ÙÙŠ Ù…Ø­ØªÙˆÙ‰ Ø£ÙƒØ«Ø± Ø§Ø¨ØªÙƒØ§Ø±Ù‹Ø§ ÙˆØ¹Ù†Ø§ÙˆÙŠÙ† Ù…Ù…ÙŠØ²Ø© Ù„ØªØ¨Ø±Ø² ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚! âœ¨"
        else:
            insights['title_repetition_detected'] = False
    else:
        insights['most_frequent_keywords'] = []
        insights['title_repetition_detected'] = False

    # Unique Channels Analysis (Detecting monopolization)
    if channel_names:
        unique_channels = set(channel_names)
        num_unique_channels = len(unique_channels)
        insights['num_unique_channels'] = num_unique_channels
        if video_count > 0 and num_unique_channels < (video_count / 2) and num_unique_channels > 1: # If less than half the videos are from unique channels
            insights['channel_monopolization_warning'] = True
            opportunity_message += f"\n\nâš ï¸ ØªØ­Ø°ÙŠØ±: Ø¹Ø¯Ø¯ Ù‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ù‚Ù†ÙˆØ§Øª ØªÙ‡ÙŠÙ…Ù† Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ({num_unique_channels} Ù‚Ù†Ø§Ø© ÙØ±ÙŠØ¯Ø© Ù…Ù† Ø£ØµÙ„ {video_count} ÙÙŠØ¯ÙŠÙˆ). Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø³ÙˆÙ‚ ÙŠÙ‡ÙŠÙ…Ù† Ø¹Ù„ÙŠÙ‡ Ù„Ø§Ø¹Ø¨ÙˆÙ† ÙƒØ¨Ø§Ø±ØŒ Ù…Ù…Ø§ ÙŠØµØ¹Ø¨ Ø§Ù„Ù…Ù†Ø§ÙØ³Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©."
        elif num_unique_channels == 1 and video_count > 1:
            insights['channel_monopolization_warning'] = True
            opportunity_message += f"\n\nğŸš¨ Ø§Ù„Ø³ÙˆÙ‚ ÙŠØ­ØªÙƒØ±Ù‡ Ù‚Ù†Ø§Ø© ÙˆØ§Ø­Ø¯Ø©: Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ù† Ù†ÙØ³ Ø§Ù„Ù‚Ù†Ø§Ø©. Ù‡Ø°Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ­Ø¯ÙŠÙ‹Ø§ ÙƒØ¨ÙŠØ±Ø§Ù‹ Ù„Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ø³ÙˆÙ‚ Ù…Ø§ Ù„Ù… ØªÙ‚Ø¯Ù… Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹."
        else:
            insights['channel_monopolization_warning'] = False
    else:
        insights['num_unique_channels'] = 0
        insights['channel_monopolization_warning'] = False

    # Recent Video Activity (Based on published_times) - Now explicitly for last 30 days
    if published_times and video_count > 0:
        recent_videos_30_days = 0
        current_date = datetime.now()

        def parse_published_time(pt_str):
            pt_lower = pt_str.lower()
            num_match = re.search(r'(\d+)', pt_lower)
            if not num_match:
                return None # Cannot parse if no number

            num = int(num_match.group(1))
            
            if "minute" in pt_lower:
                return current_date - timedelta(minutes=num)
            elif "hour" in pt_lower:
                return current_date - timedelta(hours=num)
            elif "day" in pt_lower:
                return current_date - timedelta(days=num)
            elif "week" in pt_lower:
                return current_date - timedelta(weeks=num)
            elif "month" in pt_lower:
                return current_date - timedelta(days=num * 30) # Approximation
            elif "year" in pt_lower:
                return current_date - timedelta(days=num * 365) # Approximation
            return None # Cannot parse

        for pt in published_times:
            parsed_date = parse_published_time(pt)
            if parsed_date and (current_date - parsed_date).days <= 30:
                recent_videos_30_days += 1

        insights['recent_videos_30_days_count'] = recent_videos_30_days
        insights['recent_videos_30_days_percentage'] = (recent_videos_30_days / video_count) * 100 if video_count > 0 else 0

        if recent_videos_30_days > (video_count * 0.2): # If more than 20% are recent (last 30 days)
            insights['high_recent_activity'] = True
            opportunity_message += f"\n\nğŸ“ˆ Ù†Ø´Ø§Ø· Ø­Ø¯ÙŠØ«: Ù‡Ù†Ø§Ùƒ {recent_videos_30_days} ÙÙŠØ¯ÙŠÙˆ ({insights['recent_videos_30_days_percentage']:.1f}%) ØªÙ… Ù†Ø´Ø±Ù‡Ø§ Ø®Ù„Ø§Ù„ Ø¢Ø®Ø± 30 ÙŠÙˆÙ…Ù‹Ø§. ÙŠØ´ÙŠØ± Ù‡Ø°Ø§ Ø¥Ù„Ù‰ Ø§Ù‡ØªÙ…Ø§Ù… Ù…ØªØ²Ø§ÙŠØ¯ Ø¨Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø£Ùˆ Ù…Ù†Ø§ÙØ³Ø© Ø¬Ø¯ÙŠØ¯Ø©."
        else:
            insights['high_recent_activity'] = False
    else:
        insights['recent_videos_30_days_count'] = 0
        insights['recent_videos_30_days_percentage'] = 0
        insights['high_recent_activity'] = False

    # Sentiment Analysis on Titles (Combined Video + News)
    all_titles = []
    if video_titles:
        all_titles.extend(video_titles)
    if article_titles:
        all_titles.extend(article_titles)
        
    if all_titles:
        positive_titles = 0
        negative_titles = 0
        neutral_titles = 0
        for title in all_titles:
            analysis = TextBlob(title) # Default English sentiment
            # For Arabic sentiment, might need specific TextBlob models or custom logic
            # For simplicity, using default which might be less accurate for pure Arabic
            if analysis.sentiment.polarity > 0.1: # Positive threshold
                positive_titles += 1
            elif analysis.sentiment.polarity < -0.1: # Negative threshold
                negative_titles += 1
            else:
                neutral_titles += 1
        
        insights['sentiment_analysis'] = {
            'positive_titles': positive_titles,
            'negative_titles': negative_titles,
            'neutral_titles': neutral_titles,
            'total_analyzed': len(all_titles)
        }
        
        if positive_titles > negative_titles and positive_titles > neutral_titles:
            insights['overall_sentiment'] = "Positive"
            opportunity_message += "\n\nğŸ˜Š ØªÙˆØ¬Ù‡ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ: Ø£ØºÙ„Ø¨ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ (ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙˆÙ…Ù‚Ø§Ù„Ø§Øª) ØªØ­Ù…Ù„ Ø·Ø§Ø¨Ø¹Ù‹Ø§ Ø¥ÙŠØ¬Ø§Ø¨ÙŠÙ‹Ø§."
        elif negative_titles > positive_titles and negative_titles > neutral_titles:
            insights['overall_sentiment'] = "Negative"
            opportunity_message += "\n\nğŸ˜” ØªÙˆØ¬Ù‡ Ø³Ù„Ø¨ÙŠ: Ø£ØºÙ„Ø¨ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ ØªØ­Ù…Ù„ Ø·Ø§Ø¨Ø¹Ù‹Ø§ Ø³Ù„Ø¨ÙŠÙ‹Ø§. ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ù…ÙƒØ§Ù†Ù‹Ø§ Ù„Ù„ØªÙ…ÙŠØ² Ø¨Ù…Ø­ØªÙˆÙ‰ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ."
        else:
            insights['overall_sentiment'] = "Neutral"
            opportunity_message += "\n\nğŸ˜ ØªÙˆØ¬Ù‡ Ù…Ø­Ø§ÙŠØ¯: Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ ØªØ¨Ø¯Ùˆ Ù…Ø­Ø§ÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±."
    else:
        insights['sentiment_analysis'] = {}
        insights['overall_sentiment'] = "N/A"
        
    # News Sources Analysis
    if article_sources and len(article_sources) > 0:
        unique_sources = set(article_sources)
        insights['news_sources_count'] = len(unique_sources)
        insights['news_sources'] = list(unique_sources)
        
        # Source diversity analysis
        if article_count > 0:
            source_diversity_ratio = len(unique_sources) / article_count
            insights['source_diversity_ratio'] = round(source_diversity_ratio, 2)
            
            if source_diversity_ratio < 0.3 and article_count > 5:
                opportunity_message += "\n\nğŸ“° Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª ØªØ£ØªÙŠ Ù…Ù† Ø¹Ø¯Ø¯ Ù‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±. Ù‚Ø¯ ØªÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ ÙØ±ØµØ© Ù„ØªÙ‚Ø¯ÙŠÙ… ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± Ø¬Ø¯ÙŠØ¯Ø©."
    else:
        insights['news_sources_count'] = 0
        insights['news_sources'] = []
        
    # Recent News Articles Analysis
    if article_dates and article_count > 0:
        try:
            # Convert string dates to datetime objects
            # Assuming dates are in format like '2023-01-15' or similar parseable format
            recent_articles_count = 0
            current_date = datetime.now()
            
            for date_str in article_dates:
                try:
                    # Try to parse the date - format may vary based on GoogleNews output
                    article_date = pd.to_datetime(date_str)
                    if (current_date - article_date).days <= 30:  # Articles in last 30 days
                        recent_articles_count += 1
                except:
                    # Skip dates that can't be parsed
                    continue
            
            insights['recent_articles_30_days'] = recent_articles_count
            insights['recent_articles_percentage'] = round((recent_articles_count / article_count) * 100, 1)
            
            if insights['recent_articles_percentage'] > 50:
                opportunity_message += "\n\nğŸ”¥ Ù…ÙˆØ¶ÙˆØ¹ Ø³Ø§Ø®Ù† ÙÙŠ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: {}% Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ù†ÙØ´Ø±Øª ÙÙŠ Ø¢Ø®Ø± 30 ÙŠÙˆÙ…. Ù‡Ø°Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù‡ØªÙ…Ø§Ù… Ù…ØªØ²Ø§ÙŠØ¯.".format(insights['recent_articles_percentage'])
        except Exception as e:
            print(f"Error analyzing article dates: {e}")
            insights['recent_articles_30_days'] = 0
            insights['recent_articles_percentage'] = 0

    return {"opportunity_message": opportunity_message, "insights": insights}